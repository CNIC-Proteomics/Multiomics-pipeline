{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import Libraries\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from dotmap import DotMap\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import n_colors\n",
    "\n",
    "utilsPath = r'S:\\U_Proteomica\\UNIDAD\\software\\MacrosRafa\\data\\Metabolomics\\PESA_Integromics\\Data\\utils'\n",
    "if utilsPath not in sys.path:\n",
    "    sys.path.append(utilsPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Constants\n",
    "#\n",
    "\n",
    "modes = ['cp', 'cn', 'hp']\n",
    "\n",
    "bpath = r\"S:\\U_Proteomica\\UNIDAD\\software\\MacrosRafa\\data\\Metabolomics\\PESA_Integromics\\Data\\Metabolomics\\PESA_V2\\OriginalFiles\"\n",
    "xm_path = DotMap({\n",
    "    'cp': os.path.join(bpath, 'LOESS', 'C18P', 'statTarget/shiftCor/After_shiftCor/'),\n",
    "    'cn': os.path.join(bpath, 'LOESS', 'C18N', 'statTarget/shiftCor/After_shiftCor/'),\n",
    "    'hp': os.path.join(bpath, 'LOESS', 'HILP', 'statTarget/shiftCor/After_shiftCor/'),\n",
    "})\n",
    "\n",
    "mdata_path = r'S:\\U_Proteomica\\UNIDAD\\software\\MacrosRafa\\data\\Metabolomics\\PESA_Integromics\\Data\\Metadata\\PESA_V2\\WorkingFiles\\main_metadata.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Read QC and plot values distribution\n",
    "#\n",
    "\n",
    "qc = DotMap({\n",
    "    i: pd.read_csv(os.path.join(xm_path[i], 'shift_QC_cor.csv')).iloc[:, 1:]\n",
    "    for i in modes\n",
    "})\n",
    "\n",
    "file = 'Plots/LOESS_QC.html'\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "\n",
    "for i in modes:\n",
    "    tmp = list(qc[i].groupby('batch'))\n",
    "\n",
    "    colors = n_colors('rgb(5, 200, 200)', 'rgb(200, 10, 10)', len(tmp), colortype='rgb')\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=[f'QC batch distribution | Mode: {i}', 'All batches'])\n",
    "    for data_line, color in zip(tmp, colors):\n",
    "        fig.add_trace(go.Violin(\n",
    "            x=data_line[1].iloc[:,2:].to_numpy().flatten()/1000,\n",
    "            side='positive', line_color=color, points=False, width=3, name=data_line[0]\n",
    "        ),row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Violin(\n",
    "        x=qc[i].iloc[:, 2:].to_numpy().flatten()/1000,\n",
    "        side='positive', points=False, line_color='black', showlegend=False, name=''\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    fig.add_vline(x=1, line_width=0.2, line_dash='dash')\n",
    "    fig.update_xaxes(range=(0,2))\n",
    "    \n",
    "    #fig.show()\n",
    "    with open(file, 'a') as f:\n",
    "            f.write(fig.to_html(full_html=False, include_plotlyjs='cdn', default_height='50%', default_width='80%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Read data per platform and adapt\n",
    "#\n",
    "\n",
    "xm = DotMap({\n",
    "    i: pd.read_csv(os.path.join(xm_path[i], 'shift_sample_cor.csv'))\n",
    "    for i in modes\n",
    "})\n",
    "\n",
    "mdata = pd.read_csv(mdata_path, sep='\\t')\n",
    "\n",
    "for i in xm:\n",
    "    xm[i]['sample'] = list(zip(*xm[i]['sample'].str.split('_')))[1]\n",
    "    xm[i] = pd.merge(\n",
    "        mdata[['Seqn', 'MetaboCode']],\n",
    "        xm[i],\n",
    "        how='inner', left_on='MetaboCode', right_on='sample'\n",
    "    ).drop(['MetaboCode', 'sample', 'class'], axis=1).set_index('Seqn')/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in modes:\n",
    "#     tmp = [i.split('_')[1] for i in xm[i]['sample']]\n",
    "#     tmp = [i if i[0]!='0' else i[1:] for i in tmp]\n",
    "#     xm[i].index = mdata.set_index('Name').loc[tmp]['Seqn']\n",
    "#     xm[i] = xm[i].drop(['sample', 'class'], axis=1)/1000\n",
    "\n",
    "\n",
    "# Change column names\n",
    "f2i = DotMap({\n",
    "    'cp': pd.read_excel('../OriginalFiles/RBR_f2i.xlsx', sheet_name='C18P'),\n",
    "    'cn': pd.read_excel('../OriginalFiles/RBR_f2i.xlsx', sheet_name='C18N'),\n",
    "    'hp': pd.read_excel('../OriginalFiles/RBR_f2i.xlsx', sheet_name='HILP'),\n",
    "    # 'hn': pd.read_excel('../OriginalFiles/RBR_f2i.xlsx', sheet_name='HILN')\n",
    "})\n",
    "\n",
    "for i in modes:\n",
    "    xm[i].columns = f2i[i].set_index('Name').loc[\n",
    "        xm[i].columns\n",
    "    ]['fid']\n",
    "\n",
    "for i in modes:\n",
    "    f2i[i] = f2i[i].set_index('fid').loc[xm[i].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# PCA Quality Control\n",
    "#\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "file = 'Plots/PCA_QC.html'\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "\n",
    "for i in modes:\n",
    "\n",
    "    tmp = qc[i].drop('batch', axis=1).set_index('sample').T/1000\n",
    "\n",
    "    tmp.index = f2i[i].reset_index(names='fid').set_index('Name').loc[tmp.index]['fid']\n",
    "    tmp = xm[i].T.join(\n",
    "        tmp,\n",
    "        how='inner'\n",
    "    ).T\n",
    "\n",
    "    tmp = pd.DataFrame(\n",
    "        StandardScaler().fit_transform(np.log2(tmp)),\n",
    "        index=tmp.index, columns=tmp.columns\n",
    "    )\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(tmp.to_numpy()),\n",
    "    tmp = pd.DataFrame(\n",
    "        pca.transform(tmp.to_numpy()),\n",
    "        index=tmp.index\n",
    "    )\n",
    "\n",
    "    fig = go.Figure()\n",
    "    [fig.add_trace(go.Scatter(\n",
    "        #x = tmp.loc[xm[i].index, 0],\n",
    "        #y = tmp.loc[xm[i].index, 1],\n",
    "        x = tmp.loc[s.Seqn, 0],\n",
    "        y = tmp.loc[s.Seqn, 1],\n",
    "        mode='markers', marker=dict(size=3), name=b,\n",
    "        #marker_color=mdata.set_index('Seqn').loc[xm[i].index, 'batch']\n",
    "    ))\n",
    "    for b, s in mdata.groupby('batch')]\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x = tmp.loc[qc[i]['sample'], 0],\n",
    "        y = tmp.loc[qc[i]['sample'], 1],\n",
    "        mode='markers', marker=dict(size=3), name='QC'\n",
    "    ))\n",
    "\n",
    "    fig.update_xaxes(title=f'PCA 1 ({round(pca.explained_variance_ratio_[0], 4)})')\n",
    "    fig.update_yaxes(title=f'PCA 2 ({round(pca.explained_variance_ratio_[1], 4)})')\n",
    "    fig.update_layout(width=700, title=f'{i}')\n",
    "\n",
    "    with open(file, 'a') as f:\n",
    "            f.write(fig.to_html(full_html=False, include_plotlyjs='cdn', default_height='50%', default_width='80%'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: 0\n",
      "cn: 0\n",
      "hp: 0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Missing values | They were imputed using KNN so it must be 0\n",
    "#\n",
    "\n",
    "for i in modes:\n",
    "    print(f\"{i}: {xm[i].isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp | N. observations 440\n",
      "cn | N. observations 440\n",
      "hp | N. observations 440\n",
      "\n",
      "cp | N. features 411\n",
      "cn | N. features 387\n",
      "hp | N. features 1264\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Number of observations & features per mode\n",
    "#\n",
    "\n",
    "for i in modes:\n",
    "    print(f'{i} | N. observations {xm[i].shape[0]}')\n",
    "print()\n",
    "for i in modes:\n",
    "    print(f'{i} | N. features {xm[i].shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort  Group\n",
      "2       C        60\n",
      "        D        60\n",
      "3       C        58\n",
      "        D        60\n",
      "4       C        51\n",
      "        D        51\n",
      "5       C        51\n",
      "        D        49\n",
      "dtype: int64\n",
      "\n",
      "Cohort  Group\n",
      "2       C        60\n",
      "        D        60\n",
      "3       C        58\n",
      "        D        60\n",
      "4       C        51\n",
      "        D        51\n",
      "5       C        51\n",
      "        D        49\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Que se perdio en C18P?\n",
    "#\n",
    "\n",
    "print(mdata.set_index('Seqn').loc[:, ['Cohort', 'Group']].groupby(['Cohort', 'Group']).size())\n",
    "print()\n",
    "print(mdata.set_index('Seqn').loc[xm.cp.index, ['Cohort', 'Group']].groupby(['Cohort', 'Group']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Juntar las tres matrices\n",
    "#\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "xm = reduce(lambda l, r: l.join(r, how='inner'), [xm[i] for i in modes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692', '#B6E880']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Data distribution per platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plot data distribution per platform\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "file = 'Plots/DataDistribution.html'\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "\n",
    "def plotDataDist(f, i):\n",
    "    fig = make_subplots(rows=1, cols=3, shared_yaxes=True, subplot_titles=['LOESS', 'LOESS+log2', 'LOESS+log2+CenterScal'])\n",
    "\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=xm.loc[:, f].to_numpy().flatten(),\n",
    "        xbins={'size':0.1}, opacity=0.7, marker_color=palette[0],showlegend=False, histnorm='probability density'\n",
    "    ), row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=np.log2(xm.loc[:, f].to_numpy().flatten()),\n",
    "        xbins={'size':0.1}, opacity=0.7, marker_color=palette[0],showlegend=False, histnorm='probability density'\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=StandardScaler().fit_transform(np.log2(xm.loc[:, f])).flatten(),\n",
    "        xbins={'size':0.1}, opacity=0.7, marker_color=palette[0],showlegend=False, histnorm='probability density'\n",
    "    ), row=1, col=3)\n",
    "\n",
    "\n",
    "    fig.update_xaxes(range=(-5,5))\n",
    "    fig.update_layout(title=i)\n",
    "    #fig.show()\n",
    "    with open(file, 'a') as f:\n",
    "        f.write(fig.to_html(full_html=False, include_plotlyjs='cdn', default_height='50%', default_width='80%'))\n",
    "\n",
    "\n",
    "for i in modes:\n",
    "    f = f2i[i].index\n",
    "    plotDataDist(f,i)\n",
    "\n",
    "plotDataDist(xm.columns, 'All')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Normalize data\n",
    "# \n",
    "\n",
    "xmn = pd.DataFrame(\n",
    "    StandardScaler().fit_transform(np.log2(xm)),\n",
    "    columns=xm.columns, index=xm.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check Batch Effect by Cohort\n",
    "#\n",
    "\n",
    "from PlotEDA import PlotEDA\n",
    "file = 'Plots/CohortBatchEffect.html'\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "\n",
    "plotEDA = PlotEDA(xmn, mdata, file=file)\n",
    "plotEDA.plotByGroup('batch',vl1=[0],vl2=[1], r1=(-5,5), r2=(-5,5), binsize=0.01, plotN=True)\n",
    "plotEDA = PlotEDA(xmn, mdata, file=file)\n",
    "plotEDA.plotByGroup('Cohort',vl1=[0],vl2=[1], r1=(-5,5), r2=(-5,5), binsize=0.01, plotN=True)\n",
    "plotEDA = PlotEDA(xmn, mdata, file=file)\n",
    "plotEDA.plotByGroup('Group',vl1=[0],vl2=[1], r1=(-5,5), r2=(-5,5), binsize=0.01, plotN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "catVars = ['Group', 'Smoke_dummy']\n",
    "conVars = ['Calcium_Score', 'HDL', 'LDL', 'Total_Cholesterol','Ox-LDL','Lipoprotein a','CRP', 'Plaque_thickness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: mgcv\n",
      "Loading required package: nlme\n",
      "This is mgcv 1.8-41. For overview type 'help(\"mgcv-package\")'.\n",
      "Loading required package: genefilter\n",
      "Loading required package: BiocParallel\n",
      "Warning messages:\n",
      "1: package 'sva' was built under R version 4.2.1 \n",
      "2: package 'mgcv' was built under R version 4.2.2 \n",
      "3: package 'nlme' was built under R version 4.2.2 \n",
      "4: package 'genefilter' was built under R version 4.2.2 \n",
      "5: package 'BiocParallel' was built under R version 4.2.2 \n",
      "Found4batches\n",
      "Adjusting for10covariate(s) or covariate level(s)\n",
      "Standardizing Data across genes\n",
      "Fitting L/S model and finding priors\n",
      "Finding nonparametric adjustments\n",
      "Adjusting the Data\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Adjust Cohort Batch Effect\n",
    "#\n",
    "\n",
    "from myComBat import myComBat\n",
    "\n",
    "xmnb = myComBat(xmn, mdata, 'Cohort', catVars, conVars, Rpath=os.path.join('myRData'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check Batch Effect by Cohort after \n",
    "#\n",
    "\n",
    "from PlotEDA import PlotEDA\n",
    "file = 'Plots/CohortBatchEffectComBat.html'\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "plotEDA = PlotEDA(xmn, mdata, file=file)\n",
    "plotEDA.plotByGroup('batch',vl1=[0],vl2=[1], r1=(-5,5), r2=(-5,5), binsize=0.01, plotN=True)\n",
    "plotEDA = PlotEDA(xmnb, mdata, file=file)\n",
    "plotEDA.plotByGroup('Cohort',vl1=[0],vl2=[1], r1=(-5,5), r2=(-5,5), binsize=0.01, plotN=True)\n",
    "plotEDA = PlotEDA(xmnb, mdata, file=file)\n",
    "plotEDA.plotByGroup('Group',vl1=[0],vl2=[1], r1=(-5,5), r2=(-5,5), binsize=0.01, plotN=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Write Xm normalised\n",
    "#\n",
    "\n",
    "xmnb.to_csv('Xm_norm.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Dimensionality Reduction\n",
    "#\n",
    "\n",
    "from PCA_UMAP import PCA_UMAP, PCA_Var\n",
    "\n",
    "file = 'Plots/PCA.html'\n",
    "if os.path.exists(file):\n",
    "    os.remove(file)\n",
    "\n",
    "pcaumap = PCA_UMAP(xmn, mdata, file=file)\n",
    "pcaumap.plotReduction('Cohort', pcacomp=[0,1])\n",
    "pcaumap.plotReduction('Group', pcacomp=[0,1])\n",
    "pcaumap.plotReduction('batch', pcacomp=[0,1])\n",
    "\n",
    "pcaumap = PCA_UMAP(xmnb, mdata, file=file)\n",
    "pcaumap.plotReduction('Cohort', pcacomp=[0,1], titleLabel='- Batch Corrected')\n",
    "pcaumap.plotReduction('Group', pcacomp=[0,1], titleLabel='- Batch Corrected')\n",
    "pcaumap.plotReduction('batch', pcacomp=[0,1], titleLabel='- Batch Corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%Var PCA</th>\n",
       "      <th>Calcium_Score</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>Total_Cholesterol</th>\n",
       "      <th>Ox-LDL</th>\n",
       "      <th>Lipoprotein a</th>\n",
       "      <th>CRP</th>\n",
       "      <th>Plaque_thickness</th>\n",
       "      <th>Group</th>\n",
       "      <th>Smoke_dummy</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.1619</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.4393</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.5253</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.4709</td>\n",
       "      <td>0.2913</td>\n",
       "      <td>0.2457</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7384</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.3594</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.9481</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4225</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.1753</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.7504</td>\n",
       "      <td>0.3727</td>\n",
       "      <td>0.5277</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5413</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>0.9171</td>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.1277</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4117</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.6267</td>\n",
       "      <td>0.6673</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.3907</td>\n",
       "      <td>0.7804</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.2793</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.3642</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.5665</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.6089</td>\n",
       "      <td>0.7577</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0458</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.8339</td>\n",
       "      <td>0.4325</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.9246</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>0.2356</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.7141</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>0.4045</td>\n",
       "      <td>0.4531</td>\n",
       "      <td>0.8144</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.9308</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    %Var PCA  Calcium_Score     HDL     LDL  Total_Cholesterol  Ox-LDL  \\\n",
       "1     6.1619         0.9735  0.0794  0.4393             0.0771  0.5253   \n",
       "2     5.7384         0.1041  0.2297  0.2229             0.2237  0.3594   \n",
       "3     4.4225         0.7059  0.0310  0.0279             0.0010  0.1753   \n",
       "4     3.5413         0.0677  0.0000  0.0344             0.0000  0.1487   \n",
       "5     3.1277         0.0008  0.0000  0.4117             0.0016  0.0023   \n",
       "6     2.6267         0.6673  0.0046  0.0137             0.0008  0.3907   \n",
       "7     2.3642         0.0653  0.1138  0.0020             0.0057  0.6764   \n",
       "8     2.0458         0.1162  0.7958  0.0214             0.1560  0.1286   \n",
       "9     1.8339         0.4325  0.0000  0.0263             0.0182  0.0108   \n",
       "10    1.7141         0.9256  0.7452  0.2573             0.8695  0.4045   \n",
       "\n",
       "    Lipoprotein a     CRP  Plaque_thickness   Group  Smoke_dummy  Cohort  \\\n",
       "1          0.5070  0.4709            0.2913  0.2457       0.9534  0.0055   \n",
       "2          0.5957  0.0041            0.9481  0.1812       0.0019  0.0104   \n",
       "3          0.9814  0.0592            0.7504  0.3727       0.5277  0.0002   \n",
       "4          0.0711  0.0499            0.9869  0.9171       0.4852  0.1815   \n",
       "5          0.1273  0.0003            0.0000  0.0000       0.0000  0.0000   \n",
       "6          0.7804  0.4205            0.9663  0.2793       0.8034  0.0000   \n",
       "7          0.5665  0.1856            0.6089  0.7577       0.0001  0.0001   \n",
       "8          0.7730  0.1527            0.0850  0.0368       0.0000  0.0000   \n",
       "9          0.9246  0.0093            0.3333  0.8795       0.2356  0.0000   \n",
       "10         0.4531  0.8144            0.7779  0.9308       0.2850  0.0151   \n",
       "\n",
       "    batch  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "5     0.0  \n",
       "6     0.0  \n",
       "7     0.0  \n",
       "8     0.0  \n",
       "9     0.0  \n",
       "10    0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_Var(xmn, mdata, conVars, catVars+['Cohort', 'batch'], n_comp=10).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmnb = pd.read_csv('Xm_norm.tsv', sep='\\t', index_col='Seqn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>%Var PCA</th>\n",
       "      <td>6.054992e+00</td>\n",
       "      <td>5.390977e+00</td>\n",
       "      <td>4.446299e+00</td>\n",
       "      <td>3.672196e+00</td>\n",
       "      <td>3.137663e+00</td>\n",
       "      <td>2.618348</td>\n",
       "      <td>2.250200e+00</td>\n",
       "      <td>1.958100e+00</td>\n",
       "      <td>1.857443</td>\n",
       "      <td>1.691875e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calcium_Score</th>\n",
       "      <td>1.320820e-01</td>\n",
       "      <td>8.410555e-01</td>\n",
       "      <td>1.749749e-01</td>\n",
       "      <td>2.208568e-01</td>\n",
       "      <td>9.772334e-04</td>\n",
       "      <td>0.073354</td>\n",
       "      <td>4.432940e-01</td>\n",
       "      <td>5.044842e-01</td>\n",
       "      <td>0.756365</td>\n",
       "      <td>1.635421e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDL</th>\n",
       "      <td>8.348420e-02</td>\n",
       "      <td>1.157649e-01</td>\n",
       "      <td>1.716224e-01</td>\n",
       "      <td>1.398601e-12</td>\n",
       "      <td>4.777742e-07</td>\n",
       "      <td>0.917339</td>\n",
       "      <td>1.367418e-06</td>\n",
       "      <td>5.667187e-01</td>\n",
       "      <td>0.841255</td>\n",
       "      <td>2.482104e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDL</th>\n",
       "      <td>1.555875e-01</td>\n",
       "      <td>2.340389e-01</td>\n",
       "      <td>7.220988e-02</td>\n",
       "      <td>2.199731e-02</td>\n",
       "      <td>5.559692e-01</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>6.121263e-01</td>\n",
       "      <td>3.725900e-01</td>\n",
       "      <td>0.048886</td>\n",
       "      <td>3.471312e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Cholesterol</th>\n",
       "      <td>4.755602e-02</td>\n",
       "      <td>1.456454e-02</td>\n",
       "      <td>1.446423e-02</td>\n",
       "      <td>1.189936e-05</td>\n",
       "      <td>1.498200e-03</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>9.742737e-01</td>\n",
       "      <td>9.853762e-01</td>\n",
       "      <td>0.343291</td>\n",
       "      <td>1.438837e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ox-LDL</th>\n",
       "      <td>4.528728e-01</td>\n",
       "      <td>4.509465e-01</td>\n",
       "      <td>2.968889e-01</td>\n",
       "      <td>2.384064e-01</td>\n",
       "      <td>1.961735e-03</td>\n",
       "      <td>0.366572</td>\n",
       "      <td>2.141657e-01</td>\n",
       "      <td>1.301176e-01</td>\n",
       "      <td>0.353665</td>\n",
       "      <td>3.813029e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lipoprotein a</th>\n",
       "      <td>8.644367e-01</td>\n",
       "      <td>4.450226e-01</td>\n",
       "      <td>8.437207e-01</td>\n",
       "      <td>6.551741e-02</td>\n",
       "      <td>2.231576e-01</td>\n",
       "      <td>0.678526</td>\n",
       "      <td>7.974871e-01</td>\n",
       "      <td>5.522727e-01</td>\n",
       "      <td>0.691924</td>\n",
       "      <td>1.895765e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRP</th>\n",
       "      <td>1.240818e-02</td>\n",
       "      <td>6.445078e-01</td>\n",
       "      <td>6.702184e-02</td>\n",
       "      <td>7.351270e-03</td>\n",
       "      <td>5.821384e-05</td>\n",
       "      <td>0.326823</td>\n",
       "      <td>6.737758e-01</td>\n",
       "      <td>2.685443e-01</td>\n",
       "      <td>0.637951</td>\n",
       "      <td>9.587967e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plaque_thickness</th>\n",
       "      <td>8.387849e-01</td>\n",
       "      <td>6.013457e-01</td>\n",
       "      <td>3.872929e-01</td>\n",
       "      <td>9.635614e-01</td>\n",
       "      <td>2.642998e-11</td>\n",
       "      <td>0.306880</td>\n",
       "      <td>2.684278e-01</td>\n",
       "      <td>8.320300e-01</td>\n",
       "      <td>0.962564</td>\n",
       "      <td>4.462682e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <td>1.120850e-01</td>\n",
       "      <td>8.229713e-01</td>\n",
       "      <td>4.049291e-01</td>\n",
       "      <td>8.735814e-01</td>\n",
       "      <td>3.087774e-07</td>\n",
       "      <td>0.743692</td>\n",
       "      <td>6.458080e-01</td>\n",
       "      <td>6.471211e-01</td>\n",
       "      <td>0.902013</td>\n",
       "      <td>4.547843e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke_dummy</th>\n",
       "      <td>1.159089e-02</td>\n",
       "      <td>1.364748e-02</td>\n",
       "      <td>7.897133e-01</td>\n",
       "      <td>1.512932e-01</td>\n",
       "      <td>5.411774e-18</td>\n",
       "      <td>0.191329</td>\n",
       "      <td>1.593166e-08</td>\n",
       "      <td>1.415785e-01</td>\n",
       "      <td>0.971719</td>\n",
       "      <td>1.369917e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohort</th>\n",
       "      <td>9.169473e-01</td>\n",
       "      <td>9.295528e-01</td>\n",
       "      <td>8.423443e-01</td>\n",
       "      <td>9.751874e-01</td>\n",
       "      <td>2.968938e-01</td>\n",
       "      <td>0.920574</td>\n",
       "      <td>9.516238e-01</td>\n",
       "      <td>9.860126e-01</td>\n",
       "      <td>0.949673</td>\n",
       "      <td>9.694493e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch</th>\n",
       "      <td>5.775944e-17</td>\n",
       "      <td>4.053858e-09</td>\n",
       "      <td>1.128634e-18</td>\n",
       "      <td>8.009853e-11</td>\n",
       "      <td>2.296377e-01</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>2.877046e-07</td>\n",
       "      <td>3.075880e-12</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>2.170531e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             1             2             3             4   \\\n",
       "%Var PCA           6.054992e+00  5.390977e+00  4.446299e+00  3.672196e+00   \n",
       "Calcium_Score      1.320820e-01  8.410555e-01  1.749749e-01  2.208568e-01   \n",
       "HDL                8.348420e-02  1.157649e-01  1.716224e-01  1.398601e-12   \n",
       "LDL                1.555875e-01  2.340389e-01  7.220988e-02  2.199731e-02   \n",
       "Total_Cholesterol  4.755602e-02  1.456454e-02  1.446423e-02  1.189936e-05   \n",
       "Ox-LDL             4.528728e-01  4.509465e-01  2.968889e-01  2.384064e-01   \n",
       "Lipoprotein a      8.644367e-01  4.450226e-01  8.437207e-01  6.551741e-02   \n",
       "CRP                1.240818e-02  6.445078e-01  6.702184e-02  7.351270e-03   \n",
       "Plaque_thickness   8.387849e-01  6.013457e-01  3.872929e-01  9.635614e-01   \n",
       "Group              1.120850e-01  8.229713e-01  4.049291e-01  8.735814e-01   \n",
       "Smoke_dummy        1.159089e-02  1.364748e-02  7.897133e-01  1.512932e-01   \n",
       "Cohort             9.169473e-01  9.295528e-01  8.423443e-01  9.751874e-01   \n",
       "batch              5.775944e-17  4.053858e-09  1.128634e-18  8.009853e-11   \n",
       "\n",
       "                             5         6             7             8   \\\n",
       "%Var PCA           3.137663e+00  2.618348  2.250200e+00  1.958100e+00   \n",
       "Calcium_Score      9.772334e-04  0.073354  4.432940e-01  5.044842e-01   \n",
       "HDL                4.777742e-07  0.917339  1.367418e-06  5.667187e-01   \n",
       "LDL                5.559692e-01  0.000037  6.121263e-01  3.725900e-01   \n",
       "Total_Cholesterol  1.498200e-03  0.000032  9.742737e-01  9.853762e-01   \n",
       "Ox-LDL             1.961735e-03  0.366572  2.141657e-01  1.301176e-01   \n",
       "Lipoprotein a      2.231576e-01  0.678526  7.974871e-01  5.522727e-01   \n",
       "CRP                5.821384e-05  0.326823  6.737758e-01  2.685443e-01   \n",
       "Plaque_thickness   2.642998e-11  0.306880  2.684278e-01  8.320300e-01   \n",
       "Group              3.087774e-07  0.743692  6.458080e-01  6.471211e-01   \n",
       "Smoke_dummy        5.411774e-18  0.191329  1.593166e-08  1.415785e-01   \n",
       "Cohort             2.968938e-01  0.920574  9.516238e-01  9.860126e-01   \n",
       "batch              2.296377e-01  0.000137  2.877046e-07  3.075880e-12   \n",
       "\n",
       "                         9             10  \n",
       "%Var PCA           1.857443  1.691875e+00  \n",
       "Calcium_Score      0.756365  1.635421e-01  \n",
       "HDL                0.841255  2.482104e-02  \n",
       "LDL                0.048886  3.471312e-01  \n",
       "Total_Cholesterol  0.343291  1.438837e-01  \n",
       "Ox-LDL             0.353665  3.813029e-01  \n",
       "Lipoprotein a      0.691924  1.895765e-01  \n",
       "CRP                0.637951  9.587967e-01  \n",
       "Plaque_thickness   0.962564  4.462682e-02  \n",
       "Group              0.902013  4.547843e-01  \n",
       "Smoke_dummy        0.971719  1.369917e-03  \n",
       "Cohort             0.949673  9.694493e-01  \n",
       "batch              0.000323  2.170531e-07  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PCA_UMAP import PCA_Var\n",
    "PCA_Var(xmnb, mdata, conVars, catVars+['Cohort', 'batch'], n_comp=10).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "299fabdee10379681b2207a83aa9f93c313ee5d5504e286e44b436bd7e45d8f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
