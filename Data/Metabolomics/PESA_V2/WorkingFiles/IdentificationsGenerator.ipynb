{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import Libraries\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "from dotmap import DotMap\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Constants\n",
    "#\n",
    "\n",
    "modes = ['C18N', 'C18P', 'HILP']\n",
    "f2i_path = r\"S:\\U_Proteomica\\UNIDAD\\software\\MacrosRafa\\data\\Metabolomics\\PESA_Integromics\\Data\\Metabolomics\\PESA_V2\\OriginalFiles\\RBR_f2i.xlsx\"\n",
    "\n",
    "alid_path = r\"S:\\U_Proteomica\\UNIDAD\\software\\MacrosRafa\\data\\Metabolomics\\PESA_Integromics\\Data\\Metabolomics\\PESA_V2\\OriginalFiles\\RBR_V1_Identifications.xlsx\"\n",
    "\n",
    "tp_path = r\"S:\\U_Proteomica\\UNIDAD\\software\\MacrosRafa\\data\\Metabolomics\\PESA_Integromics\\Data\\Metabolomics\\PESA_V2\\WorkingFiles\\Identifications\\TP_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature information (fid, rt, apex)\n",
    "\n",
    "f2i = DotMap({\n",
    "    i: pd.read_excel(f2i_path, sheet_name=i)\n",
    "    for i in modes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO TENEMOS IDENTIFICACIONES DE ALESSIA, POR LO QUE OMITIMOS ESTA PARTE HASTA NUEVA ORDEN\n",
    "\n",
    "# Alessia manual identifications\n",
    "\n",
    "# alid = pd.read_excel(alid_path, sheet_name='Sheet3')\n",
    "\n",
    "# alid['Name'] = [i[0]+i[2:] for i in alid['Name']]\n",
    "\n",
    "# alid['Platform'] = [{\n",
    "#     'HILIC+':'HILP',\n",
    "#     'C18+':'C18P',\n",
    "#     'C18-':'C18N'\n",
    "# }[i]\n",
    "# for i in alid['Platform']]\n",
    "\n",
    "# alid = {i[0]:i[1] for i in alid.groupby('Platform')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information from Aless\n",
    "\n",
    "# for i in modes:\n",
    "#     f2i[i] = pd.merge(\n",
    "#         f2i[i],\n",
    "#         alid[i].drop(['Apex m/z', 'RT [min]', 'Platform'], axis=1),\n",
    "#         on='Name',\n",
    "#         how='left'\n",
    "#     ).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = modes[0]\n",
    "\n",
    "tp = {\n",
    "    i: pd.read_csv(\n",
    "        os.path.join(tp_path, i, [filename for filename in os.listdir(os.path.join(tp_path, i)) if 'TPFilter' in filename][0]),\n",
    "        sep='\\t', low_memory=False\n",
    "    ).loc[:, ['FeatureInfo_Name','Name','Peptide','Halogenated','Plant','NaturalProduct','MDM','Drug','Food','Adduct','TP_Class_argmax','TPMetrics']]\n",
    "    for i in modes\n",
    "}\n",
    "\n",
    "tp = {\n",
    "    i: tp[i].fillna('')\\\n",
    "        .groupby('FeatureInfo_Name')\\\n",
    "            .agg(lambda x: ' | '.join([str(i) for i in list(x)]))\\\n",
    "                .reset_index()\\\n",
    "                    .rename(columns={'Name': 'TP_ID', 'Adduct':'TP_Adduct', 'FeatureInfo_Name':'fid'})\n",
    "    for i in modes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in modes:\n",
    "    f2i[i] = pd.merge(\n",
    "        f2i[i],\n",
    "        tp[i],\n",
    "        on='fid',\n",
    "        how='left'\n",
    "    ).fillna('UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2i = pd.concat([\n",
    "    f2i[i] for i in modes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C18N: 470/831 (0.5656)\n",
      "C18P: 2836/3193 (0.8882)\n",
      "HILIC: 1153/2043 (0.5644)\n"
     ]
    }
   ],
   "source": [
    "(f2i.TP_ID == 'UNK').sum()\n",
    "\n",
    "_=[\n",
    "    print(f\"{i}: {(j.TP_ID=='UNK').sum()}/{j.shape[0]} ({round((j.TP_ID=='UNK').sum()/j.shape[0],4)})\") \n",
    "    for i,j in f2i.groupby('Platform')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are duplications generated by Bio_Class column\n",
    "f2i = f2i[~f2i.fid.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2i.to_csv('f2i.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "299fabdee10379681b2207a83aa9f93c313ee5d5504e286e44b436bd7e45d8f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
